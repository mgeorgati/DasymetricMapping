{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from CBS and Harmonize\n",
    "This script allows the download of data from the Statistical Offices of the Netherlands and harmonizes the selected time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\FUME\\DasymetricMapping c:\\FUME\\DasymetricMapping/grootams_ProjectData/PopData c:\\FUME\\DasymetricMapping/grootams_ProjectData/AncillaryData grootams\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os \n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import cbsodata\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "# Import variables and set paths\n",
    "currrent_path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(currrent_path)))\n",
    "from scripts.variables import base_dir, ancillary_POPdata_folder_path, ancillary_data_folder_path, city, country_Orig, engine\n",
    "from scripts.mainFunctions.basic import createFolder #, unique\n",
    "from scripts.mainFunctions.excel_sql import dfTOxls\n",
    "print(base_dir, ancillary_POPdata_folder_path, ancillary_data_folder_path, city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4966 entries, 0 to 4965\n",
      "Data columns (total 26 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Updated              4966 non-null   object\n",
      " 1   ID                   4966 non-null   int64 \n",
      " 2   Identifier           4966 non-null   object\n",
      " 3   Title                4966 non-null   object\n",
      " 4   ShortTitle           4966 non-null   object\n",
      " 5   ShortDescription     4966 non-null   object\n",
      " 6   Summary              4966 non-null   object\n",
      " 7   Modified             4966 non-null   object\n",
      " 8   MetaDataModified     4966 non-null   object\n",
      " 9   ReasonDelivery       4966 non-null   object\n",
      " 10  ExplanatoryText      4966 non-null   object\n",
      " 11  OutputStatus         4966 non-null   object\n",
      " 12  Source               4966 non-null   object\n",
      " 13  Language             4966 non-null   object\n",
      " 14  Catalog              4966 non-null   object\n",
      " 15  Frequency            4966 non-null   object\n",
      " 16  Period               4966 non-null   object\n",
      " 17  SummaryAndLinks      4966 non-null   object\n",
      " 18  ApiUrl               4966 non-null   object\n",
      " 19  FeedUrl              4966 non-null   object\n",
      " 20  DefaultPresentation  4966 non-null   object\n",
      " 21  DefaultSelection     4966 non-null   object\n",
      " 22  GraphTypes           4966 non-null   object\n",
      " 23  RecordCount          4966 non-null   int64 \n",
      " 24  ColumnCount          4966 non-null   int64 \n",
      " 25  SearchPriority       4966 non-null   object\n",
      "dtypes: int64(3), object(23)\n",
      "memory usage: 1008.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Downloading table list from CBS\n",
    "tables = pd.DataFrame(cbsodata.get_table_list())\n",
    "tables.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make selection of the above tables\n",
    "tables = tables[[\"Identifier\", \"Title\",\"ShortTitle\", \"Period\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading a subset for Migration data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for Migration Data at Neighborhood level (wijken en buurten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with key words in tables\n",
    "mask = np.column_stack([tables[\"ShortTitle\"].str.contains(\"migrat\")])\n",
    "migrat_tables = tables.loc[mask.any(axis=1)]\n",
    "outTables = base_dir + \"/{}_ProjectData/keyTables/\"\n",
    "#createFolder(outTables)\n",
    "#dfTOxls(outTables, 'MigrationTables', migrat_tables) ##### --->>> It doesn't give any results at neighborhood level <<<--- #####\n",
    "\n",
    "maskNeigh = np.column_stack([tables[\"ShortTitle\"].str.contains(\"wijk\")])\n",
    "neigh_tables = tables.loc[maskNeigh.any(axis=1)]\n",
    "#dfTOxls(outTables, 'NeighborhoodTables', neigh_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the neighborhood tables, we select those that include the key figures (Kerncijfers wijken en buurten). Some of them are for individual years others for series of years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskPop = np.column_stack([neigh_tables[\"ShortTitle\"].str.contains(\"Kerncijfers wijken en buurten\")])\n",
    "pop_tables = neigh_tables.loc[maskPop.any(axis=1)]\n",
    "pop_tablesSeries = pop_tables[pop_tables.Period.str.contains(\"-\") == True]\n",
    "pop_tablesYears = pop_tables[pop_tables.Period.str.contains(\"-\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Identifier                                    Title  \\\n",
      "3333   70904ned  Kerncijfers wijken en buurten 2009-2012   \n",
      "3334   81903NED  Kerncijfers wijken en buurten 2004-2008   \n",
      "\n",
      "                                   ShortTitle       Period  \n",
      "3333  Kerncijfers wijken en buurten 2009-2012  2009 - 2012  \n",
      "3334  Kerncijfers wijken en buurten 2004-2008    2004-2008  \n",
      "     Identifier                               Title  \\\n",
      "938    85039NED  Kerncijfers wijken en buurten 2021   \n",
      "939    84799NED  Kerncijfers wijken en buurten 2020   \n",
      "940    84583NED  Kerncijfers wijken en buurten 2019   \n",
      "941    84286NED  Kerncijfers wijken en buurten 2018   \n",
      "942    83765NED  Kerncijfers wijken en buurten 2017   \n",
      "943    83487NED  Kerncijfers wijken en buurten 2016   \n",
      "3330   83220NED  Kerncijfers wijken en buurten 2015   \n",
      "3331   82931NED  Kerncijfers wijken en buurten 2014   \n",
      "3332   82339NED  Kerncijfers wijken en buurten 2013   \n",
      "3335   80868ned  Kerncijfers wijken en buurten 2003   \n",
      "3336   70139NED  Kerncijfers wijken en buurten 2001   \n",
      "3337      37681  Kerncijfers wijken en buurten 1999   \n",
      "3338      37515  Kerncijfers wijken en buurten 1997   \n",
      "3339      37108  Kerncijfers wijken en buurten 1995   \n",
      "\n",
      "                              ShortTitle Period  \n",
      "938   Kerncijfers wijken en buurten 2021   2021  \n",
      "939   Kerncijfers wijken en buurten 2020   2020  \n",
      "940   Kerncijfers wijken en buurten 2019   2019  \n",
      "941   Kerncijfers wijken en buurten 2018   2018  \n",
      "942   Kerncijfers wijken en buurten 2017   2017  \n",
      "943   Kerncijfers wijken en buurten 2016   2016  \n",
      "3330  Kerncijfers wijken en buurten 2015   2015  \n",
      "3331  Kerncijfers wijken en buurten 2014   2014  \n",
      "3332  Kerncijfers wijken en buurten 2013   2013  \n",
      "3335  Kerncijfers wijken en buurten 2003   2003  \n",
      "3336  Kerncijfers wijken en buurten 2001   2001  \n",
      "3337  Kerncijfers wijken en buurten 1999   1999  \n",
      "3338  Kerncijfers wijken en buurten 1997   1997  \n",
      "3339  Kerncijfers wijken en buurten 1995   1995  \n"
     ]
    }
   ],
   "source": [
    "print(pop_tablesSeries)\n",
    "print(pop_tablesYears)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading a subset for migration\n",
    "For the period 2004 - 2020, we take only the even years, while for the period before 2004 we select all the available years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for separate years (2014 - 2020) + (1995 - 2003)\n",
    "id = pop_tablesYears[\"Identifier\"].tolist()\n",
    "rawDataPath = ancillary_POPdata_folder_path + '/rawDataMigration'\n",
    "createFolder(rawDataPath)\n",
    "for i in range(len(id)):\n",
    "    year = pop_tablesYears.iloc[i][\"Period\"]\n",
    "    year = int(year)\n",
    "    if year == 2019 :\n",
    "        print(id[i],year)\n",
    "        data = pd.DataFrame(\n",
    "            cbsodata.get_data(\"{}\".format(id[i])))\n",
    "        dfTOxls(rawDataPath, \"{}_keyFig\".format(year), data)   \n",
    "        \"\"\"elif year < 2013 :  \n",
    "        print(id[i],year)\n",
    "        data = pd.DataFrame(\n",
    "            cbsodata.get_data(\"{}\".format(id[i])))\n",
    "        dfTOxls(rawDataPath, \"{}_keyFig\".format(year), data)   \"\"\" \n",
    "    else:\n",
    "        print('Year: {} is not selected'.format(year))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for separate years (2014 - 2020) + (1995 - 2003)\n",
    "id = pop_tablesYears[\"Identifier\"].tolist()\n",
    "rawDataPath = ancillary_POPdata_folder_path + '/rawDataMigration'\n",
    "createFolder(rawDataPath)\n",
    "for i in range(len(id)):\n",
    "    year = pop_tablesYears.iloc[i][\"Period\"]\n",
    "    year = int(year)\n",
    "    if year > 2013 and (year% 2) == 0 :\n",
    "        print(id[i],year)\n",
    "        data = pd.DataFrame(\n",
    "            cbsodata.get_data(\"{}\".format(id[i])))\n",
    "        dfTOxls(rawDataPath, \"{}_keyFig\".format(year), data)   \n",
    "    elif year < 2013 :  \n",
    "        print(id[i],year)\n",
    "        data = pd.DataFrame(\n",
    "            cbsodata.get_data(\"{}\".format(id[i])))\n",
    "        dfTOxls(rawDataPath, \"{}_keyFig\".format(year), data)    \n",
    "    else:\n",
    "        print('Year: {} is not selected'.format(year))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for series of years (2004- 2008) + (2009-2013)\n",
    "idS = pop_tablesSeries[\"Identifier\"].tolist()\n",
    "for i in idS:\n",
    "    metadata = pd.DataFrame(cbsodata.get_meta(\"{}\".format(i), 'Perioden'))\n",
    "    years= metadata['Title'].tolist()\n",
    "    data = pd.DataFrame(\n",
    "        cbsodata.get_data(\"{}\".format(i)))\n",
    "    print(years)\n",
    "    for year in years:\n",
    "        year = int(year)\n",
    "        if (year% 2) == 0 :\n",
    "            df = data.loc[data['Perioden'] == '{}'.format(year)]\n",
    "            dfTOxls(rawDataPath, \"{}_keyFig\".format(year), df)\n",
    "        else:\n",
    "            print('Year: {} is not selected'.format(year))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"##### --->>> DOWNLOAD SUCCESFULLY COMPLETED <<<--- #####\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform join between spatial data and these fields\n",
    "You need to download the geographic data from here: # https://www.cbs.nl/nl-nl/dossier/nederland-regionaal/geografische-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "for file in os.listdir(ancillary_data_folder_path+ \"/adm/neighborhoodYears/\"):\n",
    "    name = file.split(\".\")[0]\n",
    "    print(file)\n",
    "    zf = ZipFile(ancillary_data_folder_path + \"/adm/neighborhoodYears/\" + file, 'r')\n",
    "    createFolder(ancillary_data_folder_path+ \"/adm/neighborhoodYears/\"+ name)\n",
    "    zf.extractall(ancillary_data_folder_path+ \"/adm/neighborhoodYears/\"+ name)\n",
    "    zf.close()\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\FUME\\\\DasymetricMapping/grootams_ProjectData/AncillaryData/adm/neighborhoodYears\\\\buurt_2004\\\\buurt_2004_gen.shp', 'c:\\\\FUME\\\\DasymetricMapping/grootams_ProjectData/AncillaryData/adm/neighborhoodYears\\\\buurt_2006\\\\buurt_2006_gn2.shp', 'c:\\\\FUME\\\\DasymetricMapping/grootams_ProjectData/AncillaryData/adm/neighborhoodYears\\\\buurt_2010\\\\buurt_2010_v3.shp', 'c:\\\\FUME\\\\DasymetricMapping/grootams_ProjectData/AncillaryData/adm/neighborhoodYears\\\\buurt_2012\\\\buurt_2012.shp', 'c:\\\\FUME\\\\DasymetricMapping/grootams_ProjectData/AncillaryData/adm/neighborhoodYears\\\\buurt_2014\\\\buurt_2014.shp', 'c:\\\\FUME\\\\DasymetricMapping/grootams_ProjectData/AncillaryData/adm/neighborhoodYears\\\\buurt_2016\\\\buurt_2016.shp', 'c:\\\\FUME\\\\DasymetricMapping/grootams_ProjectData/AncillaryData/adm/neighborhoodYears\\\\buurt_2018\\\\buurt_2018_v3.shp', 'c:\\\\FUME\\\\DasymetricMapping/grootams_ProjectData/AncillaryData/adm/neighborhoodYears\\\\buurt_2020\\\\buurt_2020_v2.shp', 'c:\\\\FUME\\\\DasymetricMapping/grootams_ProjectData/AncillaryData/adm/neighborhoodYears\\\\buurt_2008\\\\brt_2008_gn3.shp']\n"
     ]
    }
   ],
   "source": [
    "# Get all spatial data for neighborhoods in list\n",
    "listPath=[]\n",
    "# All files ending with .shp with depth of 2 folder\n",
    "listA=glob.glob(ancillary_data_folder_path + \"/adm/neighborhoodYears/*/buurt_*.shp\")\n",
    "listPath.extend(listA)\n",
    "# All files ending with .shp with depth of 2 folder\n",
    "listB = glob.glob(ancillary_data_folder_path + \"/adm/neighborhoodYears/*/brt_*.shp\") \n",
    "listPath.extend(listB)\n",
    "print(listPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the extend of Groot Amsterdam\n",
    "extentGrootAms = ancillary_data_folder_path + \"/adm/nuts3_grootAms.geojson\"\n",
    "s2 = gpd.read_file(extentGrootAms)\n",
    "\n",
    "neighDataPath = ancillary_POPdata_folder_path + '/neighData_keyFig'\n",
    "createFolder(neighDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Select \"2018_buurt\".\"BU_CODE\", \"2018_buurt\".geometry from \"2018_buurt\" ,  \"nuts3_grootAms\" where\n",
    "ST_Intersects( ST_Transform(\"2018_buurt\".geometry,3035),  \"nuts3_grootAms\".geom) \n",
    "AND ST_AREA(ST_Intersection(ST_Transform(\"2018_buurt\".geometry,3035),  \"nuts3_grootAms\".geom) ) > ST_AREA(ST_Transform(\"2018_buurt\".geometry,3035))/2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join data for years > 2003\n",
    "for i in listPath:\n",
    "    year= i.split('\\\\')[-2].split('_')[-1]\n",
    "    gdf = gpd.read_file(i)\n",
    "\n",
    "    gdf = gdf.iloc[: , np.r_[-1, 0:4]]\n",
    "    gdf = gdf.to_crs('epsg:3035')\n",
    "    \n",
    "    inter = gpd.overlay(gdf, s2, how='intersection') \n",
    "    path = rawDataPath + \"/{}_keyFig.xlsx\".format(year)\n",
    "    df = pd.read_excel(path, header=0)\n",
    "    ndf = df.iloc[: , 1:] \n",
    "    \n",
    "    if 'Perioden' in df.columns: \n",
    "        ndf = ndf.drop(columns=['Perioden'])\n",
    "    if 'BU_CODE' not in inter.columns:\n",
    "        print('Key column is renamed')\n",
    "        inter = inter.rename(columns={'BU_2004':'BU_CODE'})\n",
    "       \n",
    "    ngdf = inter.join(ndf.set_index('Codering_3'), on ='BU_CODE')\n",
    "    ngdf = ngdf.to_crs(3035)\n",
    "    ngdf.to_file(neighDataPath + \"/{}_grootams.gpkg\".format(year),driver='GPKG',crs=\"EPSG:3035\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join data for years<=2003\n",
    "gdf = gpd.read_file(ancillary_data_folder_path + \"/adm/neighborhoodYears/buurt_2004/buurt_2004_gen.shp\")\n",
    "gdf = gdf.iloc[: , np.r_[-1, 0:4]]\n",
    "gdf = gdf.to_crs('epsg:3035')\n",
    "inter = gpd.overlay(gdf, s2, how='intersection')\n",
    "inter.to_file(ancillary_data_folder_path + \"/adm/neighborhoodYears/buurt_2004/buurt_2004_grootams.gpkg\",driver='GPKG',crs=\"EPSG:3035\")\n",
    "years_list = [1995, 1997, 1999, 2001, 2003] \n",
    "\n",
    "for year in years_list:\n",
    "    final_year = year - 1\n",
    "    path = rawDataPath + \"/{}_keyFig.xlsx\".format(year)\n",
    "    df = pd.read_excel(path, dtype=object, header=0)\n",
    "    ndf = df.iloc[: , 1:] \n",
    "    \n",
    "    if 'Codering_3' in ndf.columns:\n",
    "        print ('All good')\n",
    "    else:\n",
    "        for col in ndf.columns:\n",
    "            if col.startswith(\"Gemeentecode_\"):\n",
    "                print('Key column is renamed')\n",
    "                ndf = ndf.rename(columns={\"{}\".format(col): \"Gemeentecode_3\"})\n",
    "            elif col.startswith(\"Wijkcode_\"):\n",
    "                print('Key column is renamed')\n",
    "                ndf = ndf.rename(columns={\"{}\".format(col): \"Wijkcode_5\"})\n",
    "            elif col.startswith(\"Buurtcode_\"):\n",
    "                print('Key column is renamed')\n",
    "                ndf = ndf.rename(columns={\"{}\".format(col): \"Buurtcode_6\"})\n",
    "            else:\n",
    "                print('NO RENAMING REQUIRED')\n",
    "        print(\"Preparing key column\")\n",
    "        ndf['Codering_3'] = ndf[['Gemeentecode_3','Wijkcode_5', 'Buurtcode_6']].astype(str).apply(lambda x : 'BU{}{}{}'.format(x[0],x[1],x[2]), axis=1)\n",
    "    \n",
    "    ndf['Codering_3'] = ndf['Codering_3'].str.replace(' ', '')\n",
    "    dfTOxls(rawDataPath , \"/{}_keyFig\".format(year), ndf)\n",
    "    \n",
    "    ngdf = inter.join(ndf.set_index('Codering_3'), on ='BU_2004')  \n",
    "    ngdf = ngdf.rename(columns={\"BU_2004\": \"BU_CODE\"})  \n",
    "    ngdf.to_file(neighDataPath + \"/{}_grootams.gpkg\".format(final_year),driver='GPKG',crs=\"EPSG:3035\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dtype from object to numeric\n",
    "listGPKG = glob.glob(neighDataPath + \"/*.gpkg\")\n",
    "for file in listGPKG:\n",
    "    geodf = gpd.read_file(file)\n",
    "    geodf.iloc[:, 14:-1] = geodf.iloc[:, 14:-1].apply(pd.to_numeric, errors='coerce')\n",
    "    geodf.to_file(file,driver='GPKG',crs=\"EPSG:3035\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcPath = ancillary_POPdata_folder_path + \"/gridCells/2018_dataVectorGrid.geojson\"\n",
    "gc = gpd.read_file(gcPath)\n",
    "ngPath = ancillary_POPdata_folder_path + \"/neighData_keyFig/2020_grootams.gpkg\"\n",
    "ng = gpd.read_file(ngPath)\n",
    "\n",
    "with open(ancillary_POPdata_folder_path + \"/gc_summary.txt\",'w') as out:\n",
    "    gc.info(buf = out)\n",
    "\n",
    "with open(ancillary_POPdata_folder_path + \"/nc_summary.txt\",'w') as out:\n",
    "    ng.info(buf = out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get overview of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngPath = ancillary_POPdata_folder_path + \"/neighData_keyFig\"\n",
    "\"\"\"df = pd.DataFrame(index=range(200))\n",
    "for file in os.listdir(ngPath):\n",
    "    print(file)\n",
    "    if file.endswith(\".gpkg\"):\n",
    "        ng = gpd.read_file(ngPath + \"/\" +file)\n",
    "        year =file.split(\"_\")[0]\n",
    "        with open(ngPath + \"/nc_summaryL.txt\",'a') as out:\n",
    "            l1= \"year: {0} --> {1} columns | {2} rows \\n\".format(year, ng.shape[1], ng.shape[0])\n",
    "            out.write(l1)\n",
    "            ng.info(buf = out)\n",
    "        with open(ngPath + \"/nc_summaryS.txt\",'a') as out:\n",
    "            l2= \"Year: {0} --> {1} columns | {2} rows \\n\".format(year, ng.shape[1], ng.shape[0])\n",
    "            out.write(l2)\n",
    "        columns = ng.columns.to_list() \n",
    "        \n",
    "        df['{}'.format(year)] = pd.Series(columns)\n",
    "        #df = df.apply(lambda col: col.drop_duplicates().reset_index(drop=True))\n",
    "        \n",
    "        \n",
    "df.to_csv(ngPath + \"/nc_summaryS.csv\")\n",
    "\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_excel(ancillary_POPdata_folder_path + \"/neighData_keyFig/abbr_codes.xlsx\", header=0)\n",
    "codes_df = codes.iloc[:,0:2]\n",
    "for index, row in codes_df.iterrows():\n",
    "    character = \"_\" + row['columnName'].split(\"_\")[-1]\n",
    "    row['columnName'] = row['columnName'].split(\"{}\".format(character))[0]\n",
    "    print(row['columnName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = dict(zip(codes_df[\"columnName\"], codes_df[\"abb\"]))\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(ngPath):\n",
    "    print(file)\n",
    "    listCol=[]\n",
    "    if file.endswith(\".gpkg\"):\n",
    "        ng = gpd.read_file(ngPath + \"/\" +file)\n",
    "        dataframe = ng.iloc[:, 11:-1]\n",
    "        keys = []\n",
    "        values = []\n",
    "        for col in dataframe.columns:\n",
    "            char = \"_\" + col.split(\"_\")[-1]\n",
    "            columnname = col.split(\"{}\".format(char))[0] \n",
    "            keys.append(col)\n",
    "            values.append(columnname) \n",
    "        dictionary1 = dict(zip(keys, values))\n",
    "        ndf = ng.copy()\n",
    "        ndf = ndf.rename(columns = dictionary1)\n",
    "        ng_new = ndf.rename(columns = dictionary)\n",
    "\n",
    "        listCol = list(set(codes_df[\"abb\"].to_list()))\n",
    "        listColA = ng.iloc[:, 0:10].columns.to_list()\n",
    "        listCol.extend(listColA)\n",
    "        listCol.append('geometry')\n",
    "        print(listCol)\n",
    "        ndfL = ng_new[ng_new.columns.intersection(listCol)]\n",
    "        ndfL = ndfL.loc[:,~ndfL.columns.duplicated()]\n",
    "        print(ndfL.head(2))\n",
    "        ndfL.to_file(ngPath + \"/cleanSelection/\" + file, driver='GPKG',crs=\"EPSG:3035\")\n",
    "    listCol.clear()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading a subset for Education data <<!!!>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with key words in tables\n",
    "maskEdu = np.column_stack([tables[\"ShortTitle\"].str.contains(\"Opleidingsniveau\")])\n",
    "edu_tables = tables.loc[maskEdu.any(axis=1)]\n",
    "dfTOxls(outTables, 'EducationTables', edu_tables) ##### --->>> It does give any results at neighborhood level <<<--- #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading a subset for Income data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with key words in tables\n",
    "maskInc = np.column_stack([tables[\"ShortTitle\"].str.contains(\"inkome\")])\n",
    "inc_tables = tables.loc[maskInc.any(axis=1)]\n",
    "dfTOxls(outTables, 'IncomeTables', inc_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_trans_new import google_translator  \n",
    "translator  = google_translator()  \n",
    "Pronounce = translator.translate('สวัสดีจีน',lang_src='th',lang_tgt='zh',pronounce=True)  \n",
    "print(Pronounce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "mig_ data = pd.DataFrame(\n",
    "        cbsodata.get_data('37325eng', \n",
    "                          filters=\"WijkenEnBuurten eq 'GM0363    '\",\n",
    "                          select=['Periods','2018']))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = pd.DataFrame(\n",
    "        cbsodata.get_data('37325eng', \n",
    "                          filters=\"WijkenEnBuurten eq 'GM0363    '\",\n",
    "                          select=['Periods','2018']))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading entire dataset (can take up to 30s)\n",
    "#data = pd.DataFrame(cbsodata.get_data('37325eng', dir=\"dir_to_save_data\"))\n",
    "# Downloading a subset\n",
    "data = pd.DataFrame(\n",
    "        cbsodata.get_data('37325eng', \n",
    "                          filters=\"WijkenEnBuurten eq 'GM0363    '\",\n",
    "                          select=['Periods','2018']))\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading entire dataset (can take up to 30s)\n",
    "data = pd.DataFrame(cbsodata.get_data('83765NED'))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading entire dataset (can take up to 30s)\n",
    "data = pd.DataFrame(cbsodata.get_data('37556'))\n",
    "print(data.head())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fb1c9b82cb8e1a44d0bb6f94c86b0bfe1e1ac98e23be009ad49cdeaefcc62b9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('spdisag_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
